---
title: '기업리뷰 수집'
author: 'Dr.Kevin'
date: '10/28/2018'
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, dpi = 300)
```

여러분은 취업에 대한 관심이 상당히 많을 것이라 생각합니다. 저는 여러 대기업 금융회사에서만 16년 넘게 근무했습니다. 여러분 입장에서는 대기업 금융회사가 겉으로 보기에는 아주 좋은 직장일 것이라 생각할 것 같습니다. 저도 대학원을 졸업하고 취업을 준비하던 시기에 삼성 금융계열사에서 돈을 많이 준다는 말에 솔깃했으니까요. 

그런데 제가 직장생활을 해보니 좋은 회사, 나쁜 회사로 구분하는 것보다는 나와 맞는 회사와 맞지 않는 회사로 구분하는 편이 낫겠다는 생각을 가지게 되었습니다. 크게 3가지로 구분하자면, 회사의 조직문화와 담당하게 될 직무, 그리고 함께 일하게 될 동료(라고 쓰여 있지만 직장상사로 바꿔 읽으면 됩니다).

취업을 할 때 담당할 직무가 결정되어 있을 수도 있지만 그렇지 않은 경우도 많을 것입니다. 하지만 함께 일할 동료는 여러분이 전혀 알 수가 없겠죠? 어렵사리 취업을 했는데 막상 회사를 다녀봐야 자신과 맞는지 안맞는지 그 때 가서야 알 수 있을 겁니다. 주변의 사람들, 그러니까 학교 선배나 어른들 말씀을 들어보면 제각각일 가능성이 높습니다. 그 이유는 각자가 경험한 내용이 제각각이기 때문입니다. 제가 여러분께 드리는 이 말씀도 마찬가지구요. 

결국 여러분은 제한된 정보만을 가지고 취업 시장에 문을 두드려야 할 것입니다. 그나마 회사만 겨우 선택할 수 있을지도 모릅니다. 회사에 입사해서 담당하게 될 직무가 결정될 수도 있으니까요. 그리고 사수는 물론, 과장님, 차장님, 부장님이 어떤 분들일지는 그야말로 며느리도 모르는 상황이 될 것입니다. 

그래서 자신이 관심있는 회사가 있다면, 그 회사를 미리 경험했던 인생 선배들의 주관적인 기업리뷰를 수집해서 분석해보는 건 어떨까요? 조금이나마 도움이 되지 않을까요? 아무튼 오늘 제가 여러분께 드릴 수 있는 것은 한 회사에 대한 리뷰를 어떻게 분석하면 좋을지에 대해 제 나름의 방법을 제시하는 것입니다. 제 방법이 정답은 아니니 여러분께서 원하는 내용을 추가하시면 더욱 훌륭한 분석 결과가 될 겁니다. 그럼 시작해볼까요? 

## 데이터 수집

데이터 분석에서 가장 중요한 것은 데이터입니다. 양질의 데이터가 되겠죠? 일단 품질은 알 수 없으니 그 점은 차치하고 온라인 상에서 수집할 수 있는 기업리뷰를 찾아보도록 합시다. 다행하게도 **잡플래닛**이라는 스타트업이 기업리뷰를 공유하고 있습니다. 사실 이 데이터의 품질에 문제를 제기하는 사람들이 좀 있습니다. 예를 들어, 기업리뷰를 남기는 회원이 그 회사에서 근무한 경험이 있는지 확인하는 절차를 거치지 않는다는 것이 있구요. 또 다른 하나는 인사팀 직원이 긍정적인 리뷰를 남기는 리스크도 있다는 것입니다. 하지만 대수의 법칙을 믿어봅시다. 비록 주관적이지만 여러 회원이 작성한 기업리뷰에는 공통점이 있을테니까요.

우리는 잡플래닛의 기업리뷰 데이터를 수집할 것입니다. 그런데 한 가지 문제가 더 있습니다. 잡플래닛은 어떤 회사에 대한 기업리뷰를 작성한 회원에게만 다른 회사의 기업리뷰를 조회할 수 있도록 한다는 것입니다. 그러므로 기업리뷰를 조회하려면 로그인을 한 상태여야 합니다. 로그인을 한 상태로 웹 크롤링하는 방법은 크게 2가지가 있는데 하나는 쿠키를 이용하는 것이고, 또 다른 하나는 RSelenium을 이용하는 것입니다. 이번 프로젝트에서는 쿠키를 이용하는 방법을 사용할 것입니다. 저의 아이디와 비밀번호로 쿠키를 얻을 것인데요. 당연하게도 저의 로그인 정보는 공개하지 않을 것이므로 만약 여러분게서 이 포스팅을 스스로 따라해보려고 한다면 잡플래닛에 회원가입을 하시고, 기업리뷰를 작성한 후에 하시기 바랍니다. 

### 크롬 개발자도구를 활용하여 HTTP 요청 정보 확인하기

[잡플래닛](https://www.jobplanet.co.kr/welcome/index)에 접속하면 다음과 같이 메인 화면이 열립니다.

![](https://raw.githubusercontent.com/MrKevinNa/MrKevinNa.github.io/master/images/2018-10-28-[특강]-기업리뷰-분석-1/jobplanet_01.png)

아직 로그인하기 전이므로 오른쪽 상단에 **로그인**이라는 메뉴가 보입니다. 로그인 메뉴를 클릭해서 로그인 화면이 열리면 **크롬 개발자도구**를 엽니다. 화면 아무 곳에서나 마우스 오른쪽 버튼을 누르면 메뉴 팝업이 뜨는데 그 중 하단의 **검사(Inspect)**를 클릭하면 크롬 개발자도구가 열립니다. **Network** 탭으로 이동한 다음 **Preserve log** 앞에 있는 라디오버튼을 체크하면 로그인할 준비가 끝났습니다. 이 작업을 하는 이유는, 로그인이 진행될 때 어떤 과정을 거치는지 확인하기 위함입니다. 이제 아이디와 비밀번호를 입력해서 로그인합니다. 그러면 크롬 개발자도구에서 아래와 같은 내용이 보일 것입니다. 

![](https://raw.githubusercontent.com/MrKevinNa/MrKevinNa.github.io/master/images/2018-10-28-[특강]-기업리뷰-분석-1/jobplanet_02.png)

화면 하단에서 **Name**의 첫 번째 항목이 **Sign_in**이며, **POST 방식**으로 HTTP 요청을 하였습니다. 주의하셔야 할 점은 로그인하기 전에 **Preserve log** 버튼을 체크하지 않으면 이 내용이 보이지 않습니다. 이제 **Sign_in** 항목을 클릭하여 상세내용을 확인해볼까요? 

![](https://raw.githubusercontent.com/MrKevinNa/MrKevinNa.github.io/master/images/2018-10-28-[특강]-기업리뷰-분석-1/jobplanet_03.png)

**Headers**탭에는 크게 4가지가 보이는데요. 가장 처음 항목인 **General**은 HTTP 요청과 응답에서 공통으로 사용되는 내용이 보입니다. 우리는 여기에서 **Request URL**만 복사할 것입니다. 그리고 마우스로 화면을 맨 마지막으로 이동시킵니다. **Request Payload**에서 우리가 로그인할 때 사용한 아이디와 비밀번호가 보입니다. 즉, HTTP 요청을 할 때 `email`과 `password`의 인자로 아이디와 비밀번호를 지정해주는 것입니다. 

![](https://raw.githubusercontent.com/MrKevinNa/MrKevinNa.github.io/master/images/2018-10-28-[특강]-기업리뷰-분석-1/jobplanet_04.png)

여기까지 잘 따라왔나요? 이제 HTTP 요청을 할 때 로그인 정보를 함께 보낸 후 쿠키를 얻을 준비 과정이 끝났습니다. 이 쿠키를 이용하면 로그인 상태로 웹 페이지 이동이 가능하므로 기업리뷰 데이터를 수집할 수 있게 됩니다. 그런데 만약 여러분이 웹 크롤링 경험이 없거나 익숙하지 않다면 지금까지의 설명을 전혀 이해하지 못할 수 있습니다. 웹 크롤링은 관련 내용에 대한 공부도 필요하지만 경험도 필요하기 때문입니다. 이번 기회로 웹 크롤링에 관심이 생겼다면 공부해보시기 바랍니다. 

이제 R코드를 이용하여 웹 데이터를 수집해보겠습니다. 

```{r message=FALSE}
# 필요한 라이브러리를 불러옵니다. 
library(httr)
library(rvest)
library(tidyverse)
```

```{r}
# 로그인 화면의 URI를 복사하여 URI 객체에 지정합니다.
URI <- 'https://www.jobplanet.co.kr/users/sign_in'
```

```{r}
# 로그인 정보를 이용하여 HTTP 요청을 합니다. 
resp <- POST(url = URI,
             body = list('user[email]' = '본인의 아이디를 입력합니다',
                         'user[password]' = '본인의 비밀번호를 입력합니다'))
```

```{r echo=FALSE}
# 로그인 정보를 이용하여 HTTP 요청을 합니다. 
resp <- POST(url = URI,
             body = list('user[email]' = 'kevin.na74@gmail.com',
                         'user[password]' = 'Sktjdgh052&'))
```

```{r}
# 응답 상태코드를 확인합니다. 200이면 정상입니다.
status_code(x = resp)
```

```{r message=FALSE}
# 쿠키만 수집하여 sess 객체에 할당합니다. 
# 앞으로 HTTP 요청할 때 sess를 활용하면 로그인 상태로 HTML을 받을 수 있습니다. 
sess <- set_cookies(.cookies = unlist(x = cookies(x = resp)))
```

참고로 `sess`는 결과가 출력되지 않도록 설정했습니다. 실습을 하면서 직접 확인하시기 바랍니다. 

### 특정 회사의 기업리뷰 수집하기 

여러분은 어떤 회사에 대해 관심이 많은가요? 이번 예제에서는 저의 첫 번째 직장인 **삼성화재**로 정했습니다. 잡플래닛 메인 페이지에서 탐색창에 **삼성화재**를 조회해보면 다음과 같은 화면이 열립니다. 

![](https://raw.githubusercontent.com/MrKevinNa/MrKevinNa.github.io/master/images/2018-10-28-[특강]-기업리뷰-분석-1/jobplanet_05.png)

화면 상단에 회사 아이콘이 4개 보입니다. 그 중에서 첫 번째 아이콘을 클릭하면 새로운 화면이 열리면서 삼성화재 기업리뷰를 조회할 수 있게 됩니다. 

![](https://raw.githubusercontent.com/MrKevinNa/MrKevinNa.github.io/master/images/2018-10-28-[특강]-기업리뷰-분석-1/jobplanet_06.png)




```{r}

```

